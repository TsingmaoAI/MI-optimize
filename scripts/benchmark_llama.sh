# python benchmark/benchmark_ceval.py --model /home/wf/models/Llama2-Chinese-13b-Chat --model-type 'llama' --device 'cuda:1' --output-json 'acc.json'
# python benchmark/benchmark_cmmlu.py --model /home/wf/models/Llama2-Chinese-13b-Chat --model-type 'llama' --device 'cuda:1' --output-json 'acc.json'
# python benchmark/benchmark_lm_eval.py --model /home/wf/models/Llama2-Chinese-13b-Chat --eval-tasks winogrande wsc273 --device 'cuda:1' --output-json 'acc.json'
# python benchmark/benchmark_ppl.py --model /home/wf/models/Llama2-Chinese-13b-Chat --device 'cuda:1' --output-json 'acc.json'
python benchmark/benchmark_latency.py --model /home/wf/models/Llama2-Chinese-13b-Chat --device 'cuda:1' --output-json 'acc.json'